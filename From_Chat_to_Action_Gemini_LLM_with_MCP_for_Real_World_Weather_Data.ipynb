{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8w/GAG8iLJu9jR3gsQVEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdnooraj14/Chat_to_Action_Gemini_LLM_with_MCP_for_Real_World_Weather_Data.ipynb/blob/main/From_Chat_to_Action_Gemini_LLM_with_MCP_for_Real_World_Weather_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests fastapi uvicorn nest_asyncio pyngrok pydantic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddZBJQ--5CcC",
        "outputId": "b93624c9-3aa9-49fc-d9a2-9cb0a17e71e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.47.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken \"32PhgA1fz04NFbvg2XfYUP7aDUo_2sKKV16XSKc4BSVfdzUyX\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwkndE9q8iAl",
        "outputId": "7fefa0ac-cca6-4038-9a4d-05436a8329e3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLnooHyc4kNv",
        "outputId": "3cfd5045-cba0-40b0-ff45-4e3bf4940f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCP Weather Server URL: NgrokTunnel: \"https://b148b9c1018b.ngrok-free.app\" -> \"http://localhost:8002\"\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio, os, requests\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI(title=\"MCP Weather Server\")\n",
        "\n",
        "class WeatherRequest(BaseModel):\n",
        "    city: str\n",
        "\n",
        "class WeatherResponse(BaseModel):\n",
        "    city: str\n",
        "    temperature: float\n",
        "    condition: str\n",
        "\n",
        "OPENWEATHER_KEY = \"d04f5b9689476f7406357c2a6d4a9585\"  # <-- put your OpenWeather key\n",
        "\n",
        "@app.post(\"/tool/get_weather\", response_model=WeatherResponse)\n",
        "def get_weather(req: WeatherRequest):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={req.city}&appid={OPENWEATHER_KEY}&units=metric\"\n",
        "    resp = requests.get(url).json()\n",
        "    if \"main\" not in resp:\n",
        "        return WeatherResponse(city=req.city, temperature=-1.0, condition=\"Not Found\")\n",
        "    return WeatherResponse(\n",
        "        city=req.city,\n",
        "        temperature=resp[\"main\"][\"temp\"],\n",
        "        condition=resp[\"weather\"][0][\"description\"].title()\n",
        "    )\n",
        "\n",
        "# Expose server\n",
        "public_url = ngrok.connect(8002)\n",
        "print(\"MCP Weather Server URL:\", public_url)\n",
        "\n",
        "# Run uvicorn in background thread\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8002)\n",
        "\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pydantic import BaseModel, ValidationError\n",
        "\n",
        "# Gemini config\n",
        "GEMINI_API_KEY = \"AIzaSyAtQZyYuLCqMjXEDIv4qBFHmT3huykEoMs\"\n",
        "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
        "GEMINI_ENDPOINT = f\"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent\"\n",
        "\n",
        "# MCP server (from ngrok output)\n",
        "MCP_SERVER = public_url\n",
        "\n",
        "# Gemini call\n",
        "def call_gemini(prompt: str) -> dict:\n",
        "    headers = {\"Authorization\": f\"Bearer {GEMINI_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "    payload = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "    resp = requests.post(GEMINI_ENDPOINT, headers=headers, json=payload)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "# Pydantic model for action\n",
        "class MCPAction(BaseModel):\n",
        "    action: str\n",
        "    tool: str\n",
        "    args: dict\n",
        "\n",
        "# MCP call\n",
        "def call_mcp_server(tool_name: str, tool_args: dict):\n",
        "    url = f\"{MCP_SERVER}/tool/{tool_name}\"\n",
        "    resp = requests.post(url, json=tool_args)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "# Orchestrator loop\n",
        "def handle_user_request(user_text: str):\n",
        "    control_prompt = f\"\"\"\n",
        "You are an assistant that can either:\n",
        "1. Answer directly if you know the answer.\n",
        "2. Or request a tool call if external info is needed.\n",
        "\n",
        "If you need external data, ONLY output JSON like:\n",
        "{{\"action\":\"call_mcp\",\"tool\":\"get_weather\",\"args\":{{\"city\":\"CityName\"}}}}\n",
        "\n",
        "If you can answer directly, reply with:\n",
        "REPLY: <your answer>\n",
        "\"\"\"\n",
        "    # Ask Gemini\n",
        "    gemini_resp = call_gemini(user_text + \"\\n\" + control_prompt)\n",
        "    output_text = gemini_resp[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].strip()\n",
        "\n",
        "    if output_text.startswith(\"{\"):\n",
        "        try:\n",
        "            action = MCPAction(**json.loads(output_text))\n",
        "            if action.action == \"call_mcp\":\n",
        "                tool_result = call_mcp_server(action.tool, action.args)\n",
        "\n",
        "                followup_prompt = f\"\"\"\n",
        "The tool returned: {json.dumps(tool_result)}\n",
        "User originally asked: {user_text}\n",
        "Now, write a clear helpful final answer for the user.\n",
        "\"\"\"\n",
        "                final = call_gemini(followup_prompt)\n",
        "                return final[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "        except ValidationError as e:\n",
        "            return f\"Validation error: {e}\"\n",
        "    elif output_text.startswith(\"REPLY:\"):\n",
        "        return output_text.replace(\"REPLY:\", \"\").strip()\n",
        "    return output_text\n"
      ],
      "metadata": {
        "id": "gh4JgBv-5vtb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "API_KEY = \"d04f5b9689476f7406357c2a6d4a9585\"\n",
        "city = \"gujarat\"\n",
        "\n",
        "# Fetch weather data\n",
        "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}&units=metric\"\n",
        "resp = requests.get(url).json()\n",
        "\n",
        "# Print raw response\n",
        "print(resp)\n",
        "\n",
        "# Calculate local sunrise and sunset\n",
        "sunrise = datetime.utcfromtimestamp(resp[\"sys\"][\"sunrise\"] + resp[\"timezone\"]).strftime('%H:%M')\n",
        "sunset = datetime.utcfromtimestamp(resp[\"sys\"][\"sunset\"] + resp[\"timezone\"]).strftime('%H:%M')\n",
        "\n",
        "print(f\"Sunrise: {sunrise}\")\n",
        "print(f\"Sunset: {sunset}\")\n",
        "\n",
        "# Optional: print user-friendly weather info\n",
        "print(f\"City: {resp['name']}\")\n",
        "print(f\"Temperature: {resp['main']['temp']}°C\")\n",
        "print(f\"Condition: {resp['weather'][0]['description'].title()}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9VcKhEW7dnn",
        "outputId": "0c5444b4-cfb6-4941-86db-28bba7f4fbed"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'coord': {'lon': 72, 'lat': 23}, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 27.63, 'feels_like': 29.63, 'temp_min': 27.63, 'temp_max': 27.63, 'pressure': 1005, 'humidity': 67, 'sea_level': 1005, 'grnd_level': 1003}, 'visibility': 10000, 'wind': {'speed': 3.98, 'deg': 240, 'gust': 6.63}, 'clouds': {'all': 98}, 'dt': 1757331932, 'sys': {'country': 'IN', 'sunrise': 1757292995, 'sunset': 1757337796}, 'timezone': 19800, 'id': 1270770, 'name': 'Gujarat', 'cod': 200}\n",
            "Sunrise: 06:26\n",
            "Sunset: 18:53\n",
            "City: Gujarat\n",
            "Temperature: 27.63°C\n",
            "Condition: Overcast Clouds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2109888436.py:15: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
            "  sunrise = datetime.utcfromtimestamp(resp[\"sys\"][\"sunrise\"] + resp[\"timezone\"]).strftime('%H:%M')\n",
            "/tmp/ipython-input-2109888436.py:16: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
            "  sunset = datetime.utcfromtimestamp(resp[\"sys\"][\"sunset\"] + resp[\"timezone\"]).strftime('%H:%M')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 5000 --log=stdout &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAqHP1vzD58k",
        "outputId": "67a7c8c9-e381-46f9-a7f2-b43468baf6ef"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m[09-08|11:22:00] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[09-08|11:22:00] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[09-08|11:22:00] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-09-08T11:22:00+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-09-08T11:22:00+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-09-08T11:22:00+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-09-08T11:22:00+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:5000 url=https://39181e0c9186.ngrok-free.app\n",
            "t=2025-09-08T11:24:18+0000 lvl=warn msg=\"failed to open private leg\" id=cd2c06a343e5 privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2025-09-08T11:24:18+0000 lvl=warn msg=\"failed to open private leg\" id=b9007362750a privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2025-09-08T11:25:58+0000 lvl=warn msg=\"failed to open private leg\" id=4ee617edca8e privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2025-09-08T11:25:59+0000 lvl=warn msg=\"failed to open private leg\" id=bee90b776716 privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2025-09-08T11:27:13+0000 lvl=warn msg=\"failed to open private leg\" id=bac1099f0339 privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2025-09-08T11:27:14+0000 lvl=warn msg=\"failed to open private leg\" id=bd57ea8a4e61 privaddr=localhost:5000 err=\"dial tcp 127.0.0.1:5000: connect: connection refused\"\n",
            "t=2025-09-08T11:34:17+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-09-08T11:34:17+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n"
          ]
        }
      ]
    }
  ]
}